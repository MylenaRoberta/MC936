{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"image_processing.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPAD83Y931PW7vacSTUc3pk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Autoria\n","\n","* Cristiano Sampaio Pinheiro, RA 256352\n","* Jhonatan Cléto, RA 256444\n","* Mylena Roberta dos Santos, RA 222687"],"metadata":{"id":"mVRY3oA6l1tS"}},{"cell_type":"markdown","source":["# Bibliotecas e Paths"],"metadata":{"id":"rkJgDG51l6lp"}},{"cell_type":"code","source":["!pip install glrlm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ya_RO5WPeDPo","executionInfo":{"status":"ok","timestamp":1657133263982,"user_tz":180,"elapsed":5736,"user":{"displayName":"Cristiano Sampaio Pinheiro","userId":"00821319322819515045"}},"outputId":"85a86e27-2459-4cb9-bd57-6e6481d26ed8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting glrlm\n","  Downloading glrlm-0.1.0-py3-none-any.whl (6.9 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from glrlm) (4.1.2.30)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glrlm) (1.21.6)\n","Installing collected packages: glrlm\n","Successfully installed glrlm-0.1.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3Ko01mxlmb8"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from PIL import Image\n","from scipy import stats\n","\n","from glrlm import GLRLM\n","from glrlm.normalizer import Normalizer\n","from glrlm.degree import Degree\n","from glrlm.operator import Operator\n","\n","from skimage.feature import greycomatrix, greycoprops\n","from skimage.feature import local_binary_pattern"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","PATH = '/content/drive/MyDrive/MC936/P4/'\n","PATH_DATA = PATH + 'data/'\n","PATH_TRAIN = PATH_DATA + 'Train/'\n","PATH_LES = PATH_DATA + 'LES/'\n","PATH_ASSETS = PATH + 'assets/'"],"metadata":{"id":"RhwIvJAqmLtJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657133495510,"user_tz":180,"elapsed":202746,"user":{"displayName":"Cristiano Sampaio Pinheiro","userId":"00821319322819515045"}},"outputId":"bf1c304b-782e-4d9a-f75d-a513c9f41352"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Obtem Imagens Previamente Selecionadas"],"metadata":{"id":"6H185knsOmqi"}},{"cell_type":"markdown","source":["Partindo do dataframe gerado após a seleção das imagens é construída uma lista de imagens com suas respectivas máscaras, tal estrutura é salva em dicionários para cada lesão com uma chave para cada paciente."],"metadata":{"id":"HUGutepJQc31"}},{"cell_type":"code","source":["def img_dict(imgs:list, masks:list, areas:list) -> dict:\n","  \"\"\"\n","    ## Descrição:\n","     - Constrói um dicionário com as imagens, máscaras e\n","     tamanho das máscaras de cada paciente no conjunto\n","\n","    ## Entrada:\n","     - imgs: Lista com os paths de todas as imagens\n","     do conjunto\n","     - masks: Lista com os paths das máscaras do\n","     conjunto\n","     - areas: Lista com o tamanho das máscaras do\n","     conjunto\n","    \n","    ## Saída:\n","     - img_dict: dicionário em que as chaves são os ids\n","     dos pacientes e os valores são dicionários contendo\n","     listas das imagens, máscaras e áreas das máscaras\n","     dos cortes selecionadas para cada paciente\n","  \"\"\"\n","\n","  img_dict = dict()\n","\n","  for i in range(len(imgs)):\n","    imp = imgs[i]\n","    pnum = imp[:3] # obtem o id do paciente\n","\n","    if pnum in img_dict.keys():\n","      img_dict[pnum]['imgs'].append(imp)  \n","      img_dict[pnum]['masks'].append(masks[i])\n","      img_dict[pnum]['areas'].append(areas[i])\n","\n","    else:\n","      dt = {\n","            'imgs': [imp],\n","            'masks': [masks[i]],\n","            'areas': [areas[i]]\n","           }\n","      \n","      img_dict[pnum] = dt\n","\n","  return img_dict"],"metadata":{"id":"LxdbK1o6RGEC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Abrir csvs pré-computados\n","avc_set_df = pd.read_csv(PATH_DATA + \"avc_set_df.csv\")\n","em_set_df = pd.read_csv(PATH_DATA + \"em_set_df.csv\")\n","les_set_df = pd.read_csv(PATH_DATA + \"les_set_df.csv\")\n","\n","# Retira máscaras totalmente pretas\n","values = ['610_FLAIR26_mask.png', '611_FLAIR15_mask.png', '611_FLAIR16_mask.png']\n","les_set_df = les_set_df[les_set_df.masks.isin(values) == False]\n","les_set_df.reset_index(inplace=True)\n","\n","# Obter lista de imagens\n","avc_imgs = avc_set_df['imgs']\n","avc_masks = avc_set_df['masks']\n","avc_areas = avc_set_df['areas']\n","em_imgs = em_set_df['imgs']\n","em_masks = em_set_df['masks']\n","em_areas = em_set_df['areas']\n","les_imgs = les_set_df['imgs']\n","les_masks = les_set_df['masks']\n","les_areas = les_set_df['areas']\n","\n","# Dicionários com as imagens separadas por paciente\n","avc_dict = img_dict(avc_imgs, avc_masks, avc_areas)\n","em_dict = img_dict(em_imgs, em_masks, em_areas)\n","les_dict = img_dict(les_imgs, les_masks, les_areas)\n","\n","print(\"Num Pacientes AVC: \", len(avc_dict))\n","print(\"Num Pacientes EM: \", len(em_dict))\n","print(\"Num Pacientes LES: \", len(les_dict))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PF5ntPc2RGgY","executionInfo":{"status":"ok","timestamp":1657135472146,"user_tz":180,"elapsed":2615,"user":{"displayName":"Cristiano Sampaio Pinheiro","userId":"00821319322819515045"}},"outputId":"031a6b52-3e64-4ec6-b0f7-2539dba45fdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num Pacientes AVC:  50\n","Num Pacientes EM:  51\n","Num Pacientes LES:  78\n"]}]},{"cell_type":"markdown","metadata":{"id":"GzfyXj9uC9Fv"},"source":["# Aplica Máscaras"]},{"cell_type":"markdown","metadata":{"id":"WKj9hwJsV4v4"},"source":["As máscara são aplicadas nas imagens através de uma simples mutiplicação de matrizes, para eliminar a grande quantidade de preto resultante dessa operação realizamos um crop na imagem. Os limites para esse corte são determinados pelos primeiros pixels com cor diferente de preto."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5Ne26ykCf3-"},"outputs":[],"source":["# Função para aplicação das máscaras e crop das imagens de maneira individual\n","from typing import Tuple\n","\n","def get_crop_limits(mask_mat: np.array) -> Tuple[int, int, int, int]:\n","    \"\"\"\n","      ## Descrição:\n","      - Obtem as coordenadas dos limites das lesões através da máscara\n","\n","      ## Entrada:\n","      - mask_mat: np.array com a máscara\n","\n","      ## Saída:\n","      - min_y: inteiro correspondente a coordenada do limite inferior \n","      - min_x: inteiro correspondente a coordenada do limite esquerdo \n","      - max_y: inteiro correspondente a coordenada do limite superior \n","      - max_x: inteiro correspondente a coordenada do limite direito \n","    \"\"\"\n","    # Obtem índices de elementos diferentes de 0\n","    white_pt_coords=np.argwhere(mask_mat)\n","\n","    # Obtem limites\n","    min_y = min(white_pt_coords[:,0])\n","    min_x = min(white_pt_coords[:,1])\n","    max_y = max(white_pt_coords[:,0])\n","    max_x = max(white_pt_coords[:,1])\n","    \n","    return min_y, min_x, max_y, max_x\n","\n","\n","def apply_mask(img_name: str, mask_name: str, path: str, group='') -> np.array:\n","  \"\"\"\n","    ## Descrição:\n","     - Abre uma imagem e sua respectiva máscara, as converte para np.array e\n","     realiza a multiplicação dos arrays já aplicando um crop no resultado\n","\n","    ## Entrada:\n","     - img_name: String contendo o nome da imagem\n","     - mask_name: String contendo o nome da máscara\n","     - path: String contendo o caminho para importar o arquivo\n","     - group: String usada para compor o caminho para acessar imagens de \n","     diferentes grupos\n","\n","    ## Saída:\n","     - crop_mask_img: np.array contendo o resultado da multiplicação dos arrays \n","     devidamente dimensionado\n","  \"\"\"\n","\n","  # Abre imagens\n","  img = Image.open(path + group + '/' + img_name)\n","  mask = Image.open(path + group + '/' + mask_name)\n","\n","  # Converte imagens para array\n","  img_mat = np.array(img, dtype=np.uint8)\n","  mask_mat = np.array(mask, dtype=np.uint8)\n","\n","  if(path!=PATH_LES):\n","    mask_mat = mask_mat-253 # Realiza correção em algumas máscaras\n","\n","  # Obtem limites para o crop da imagem\n","  min_y, min_x, max_y, max_x = get_crop_limits(mask_mat)\n","\n","  # Realiza mutiplicação e delimita imagem resultante\n","  crop_mask_img = (mask_mat * img_mat)[min_y:max_y,min_x:max_x]\n","\n","  return crop_mask_img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCTdkfjLC2r9"},"outputs":[],"source":["# Cria dicionários com os ROIs das imagens\n","avc_roi_dict = {}\n","em_roi_dict = {}\n","les_roi_dict = {}\n","\n","# Percorre dicionários com as informações referentes aos pares imagem/máscara gerando os ROIs \n","for patient in avc_dict.keys():\n","  aux_imgs = []\n","  aux_areas = []\n","  for i in range(len(avc_dict[patient]['imgs'])):\n","    aux_imgs.append(apply_mask(avc_dict[patient]['imgs'][i], avc_dict[patient]['masks'][i], PATH_TRAIN, 'AVC'))\n","    aux_areas.append(avc_dict[patient]['areas'][i])\n","  avc_roi_dict[patient] = {'roi_imgs':aux_imgs, 'areas': aux_areas}\n","\n","for patient in em_dict.keys():\n","  aux_imgs = []\n","  aux_areas = []\n","  for i in range(len(em_dict[patient]['imgs'])):\n","    aux_imgs.append(apply_mask(em_dict[patient]['imgs'][i], em_dict[patient]['masks'][i], PATH_TRAIN, 'EM'))\n","    aux_areas.append(em_dict[patient]['areas'][i])\n","  em_roi_dict[patient] = {'roi_imgs':aux_imgs, 'areas': aux_areas}\n","\n","for patient in les_dict.keys():\n","  aux_imgs = []\n","  aux_areas = []\n","  for i in range(len(les_dict[patient]['imgs'])):\n","    aux_imgs.append(apply_mask(les_dict[patient]['imgs'][i], les_dict[patient]['masks'][i], PATH_LES))\n","    aux_areas.append(les_dict[patient]['areas'][i])\n","  les_roi_dict[patient] = {'roi_imgs':aux_imgs, 'areas': aux_areas}"]},{"cell_type":"markdown","metadata":{"id":"fw75JB6DDBPE"},"source":["# Extração de Atributos"]},{"cell_type":"markdown","metadata":{"id":"kSjx6ab4Wqky"},"source":["Ainda que a quantidade de pixels pretos nas imagens tenha diminuído após a aplicação das máscaras, executamos os métodos de extração de features de maneira a não considerar esses pixels. Como as lesões estão concentradas próximas à cor branca, a princípio os pixels pretos não agregarão na identificação e classificação dessas lesões, ainda, no caso de múltiplas lesões com um grande espaçamento, o background pode trazer um ruído considerável para os dados obtidos."]},{"cell_type":"markdown","metadata":{"id":"JBjNep6SgCff"},"source":["## Extraindo Atributos de Histogramas"]},{"cell_type":"markdown","source":["Os histogramas das imagens foram confeccionados utilizando a função _[histogram](https://numpy.org/doc/stable/reference/generated/numpy.histogram.html)_ da biblioteca _numpy_, a qual computa um histograma a partir de um dataset, no caso um numpy.array. Os pixels pretos foram eliminados do próprio array, de modo que o valor 0 foi desconsiderado na montagem do histograma. \n","\n","Com os histogramas montados suas features foram extraídas utilizando a função _[stats.describe](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.describe.html)_ da biblioteca _scipy_. Com isso foi possível obter as informações de nobs, minmax, mean, variance, skewness e kurtosis.\n"],"metadata":{"id":"CfDNM_iwc0XX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BZLsJhJDHZE"},"outputs":[],"source":["# Funções para montar e extrair features relacionadas aos histogramas das imagens\n","def make_hist(imgs: list) -> list:\n","  \"\"\"\n","    ## Descrição:\n","     - Obtem lista de histogramas a partir das imagens recebidas\n","\n","    ## Entrada:\n","     - imgs: Lista de np.array correspondentes aos ROIs das imagens\n","    \n","    ## Saída:\n","     - htgs: Lista de dicionários contendo o histograma e bins\n","     para cada imagem\n","  \"\"\"\n","\n","  # Cria estrutura para armazenar histogramas\n","  htgs = []\n","  nbins = 20\n","\n","  # Percorre imagens gerando histogramas\n","  for i in range(len(imgs)):\n","    # Elimina pixels pretos da imagem\n","    img = imgs[i][imgs[i]>0]\n","    # Confecciona histograma\n","    h, bin_edges = np.histogram(img, nbins,(0,255))\n","    htgs.append({'hist': h, 'bins': bin_edges})\n","\n","  return htgs\n","\n","def get_hists_features(imgs: list) -> list:\n","  \"\"\"\n","    ## Descrição:\n","     - Obtem lista de features provenientes de histogramas \n","     construídos a partir das imagens recebidas\n","\n","    ## Entrada:\n","     - imgs: Lista de np.array correspondentes aos ROIs das imagens\n","    \n","    ## Saída:\n","     - hists_features: Lista de dicionários contendo as features dos histogramas\n","  \"\"\"\n","\n","  # Cria estrutura para armazenar as features dos histogramas\n","  hists_features = []\n","  hists = make_hist(imgs)\n","  # Percorre histrogramas de um conjunto de imagens extraindo suas features\n","  for i in range(len(hists)):\n","    describe = stats.describe(hists[i]['hist'])._asdict()\n","    hists_features.append( {'min': describe['minmax'][0],\n","                            'max': describe['minmax'][1],\n","                            'mean': describe['mean'],\n","                            'variance': describe['variance'],\n","                            'skewness': describe['skewness'],\n","                            'kurtosis': describe['kurtosis']} )\n","  \n","  return hists_features"]},{"cell_type":"markdown","metadata":{"id":"TdNmf3J5NHsy"},"source":["## Extraindo Atributos de Textura"]},{"cell_type":"markdown","source":["Dos atributos de textura, fizemos uso da Matriz de Coocorrência (GLCM), Matriz de Comprimento de Corrida (GLRLM) e Local Binary Pattern (LBP)."],"metadata":{"id":"FfQZ0hT0dc7a"}},{"cell_type":"markdown","metadata":{"id":"Vo6TbdQZgHf1"},"source":["### Atributos Matriz de Coocorrência (GLCM)"]},{"cell_type":"markdown","source":["Para obter os atributos provenientes da  Matriz de Coocorrência (GLCM), fizemos uso da função _[greycomatrix](https://scikit-image.org/docs/0.7.0/api/skimage.feature.texture.html)_\n","também da biblioteca _skimage_, essa função retorna um array que é utilizado pela função \n","_greycoprops_ para obter as informações de contrast, correlation, energy e homogeneity. Visando descartar os pixels pretos, o array retornado pela primeira função foi modificado, eliminando os dados provenientes deles. Ainda, esse método pode variar de acordo com o ângulo, no entanto, para o domínio estudo essa variação não deve causar mudanças, desse modo, o GLCM foi calculado para os 4 ângulos, 0º, 45º, 90º e 135º, e os valores obtidos em cada caso foram acumulados. \n"],"metadata":{"id":"2t6pqI1bdead"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-8zLCg-QIk6_"},"outputs":[],"source":["# Função para extrair features da Matriz de Coocorrência (GLCM) das imagens\n","def get_GLCM_features(imgs: list) -> list:\n","  \"\"\"\n","  ## Descrição:\n","    - Obtem features provenientes da GLCM a partir das imagens recebidas\n","\n","  ## Entrada:\n","    - imgs: Lista de np.array correspondentes aos ROIs das imagens\n","  \n","  ## Saída:\n","    - glcm_features: Lista de dicionários contendo as features extraídas da GLCM\n","  \"\"\"\n","\n","  # Cria estrutura para armazenar as features\n","  glcm_features = []\n","\n","  # Percorre imagens aplicando a GLCM\n","  for i in range(len(imgs)):\n","    # Cálculo das matrizes de co-ocorrência sem realizar normalização\n","    glcm = greycomatrix(imgs[i], distances = [1], \n","                        angles = np.deg2rad([0, 45, 90, 135]), \n","                        levels = 256, symmetric = True, normed = False)\n","    \n","    # Elimina pixels pretos da imagem\n","    glcm_br = glcm[1:, 1:, :, :]\n","    \n","    glcm_br_norm = np.true_divide(glcm_br, glcm_br.sum(axis=(0, 1)))\n","\n","    # Contraste: diferença entre os tons de cinza\n","    contrast = greycoprops(glcm_br_norm, prop = 'contrast')\n","\n","    # Correlação: dependência linear dos tons de cinza\n","    correlation = greycoprops(glcm_br_norm, prop = 'correlation')\n","\n","    # Energia: uniformidade da textura\n","    energy = greycoprops(glcm_br_norm, prop = 'energy')\n","\n","    # Homogeneidade: variações na textura (inversamente proporcional ao resultado)\n","    homogeneity = greycoprops(glcm_br_norm, prop = 'homogeneity')\n","    \n","    glcm_features.append({'contrast_sum': sum(contrast[0]),\n","                          'correlation_sum': sum(correlation[0]),\n","                          'energy_sum': sum(energy[0]),\n","                          'homogeneity_sum': sum(homogeneity[0])})\n","  \n","  return glcm_features"]},{"cell_type":"markdown","metadata":{"id":"_mWEv0mLgjDH"},"source":["### Atributos Matriz de Comprimento de Corrida (GLRLM)"]},{"cell_type":"markdown","source":["Os atributos provenientes da Matriz de Comprimento de Corrida (GLRLM) foram extraídos fazendo uso da biblioteca _[GLRLM](https://github.com/eiproject/python-glrlm)_, aqui vale ressaltar que não usamos uma função diretamente. Estudando o código da função _glrlm_ dessa biblioteca, percebemos que seria possível eliminar os pixels pretos aplicando os métodos da função de maneira independente, assim, em um passo intermediária seria possível acessar a matriz resultante e excluir os valores referentes a tais pixels, para então extrair os atributos desejados. Assim obtemos os atributos sre, lre, glu, rlu e rpc."],"metadata":{"id":"u2HXGCzCdv32"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmAJ7Qt_5Thh"},"outputs":[],"source":["# Função para extrair features da Matriz de Comprimento de Corrida (GLRLM) das imagens\n","degree  = Degree()\n","operator = Operator()\n","normalizer = Normalizer()\n","\n","def get_GLRLM_features(imgs: list) -> list:\n","  \"\"\"\n","  ## Descrição:\n","    - Obtem features provenientes da GLRLM a partir das imagens recebidas\n","\n","  ## Entrada:\n","    - imgs: Lista de np.array correspondentes aos ROIs das imagens\n","  \n","  ## Saída:\n","    - glrlm_features: Lista de dicionários contendo as features extraídas da GLRLM\n","  \"\"\"\n","\n","  # Cria estrutura para armazenar as features\n","  glrlm_features = []\n","  level = 256\n","\n","  # Percorre imagens aplicando a GLRLM\n","  for i in range(len(imgs)):\n","    # Execulta funções da biblioteca de maneira individual\n","    normalized_image = normalizer.normalizationImage(imgs[i], 0, level)\n","    degree_obj = degree.create_matrix(normalized_image, level)\n","    \n","    # Elimina pixels pretos da imagem\n","    newDegrees = []\n","    for mat in degree_obj.Degrees:\n","      newDegrees.append( mat[1:,:] )\n","    degree_obj.Degrees = newDegrees\n","    \n","    feature_obj = operator.create_feature(degree_obj)\n","\n","    sre, lre, glu, rlu, rpc = feature_obj.Features\n","    glrlm_features.append({'sre': sre,\n","                           'lre': lre,\n","                           'glu': glu,\n","                           'rlu': rlu,\n","                           'rpc': rpc})\n","  \n","  return glrlm_features"]},{"cell_type":"markdown","metadata":{"id":"Mx3HxTiPhtHG"},"source":["### Atributos Local Binary Pattern (LBP)"]},{"cell_type":"markdown","source":["As features extraídas do Local Binary Pattern (LBP) são provenientes de histogramas, de modo que após fazer uso da função _[local_binary_pattern](https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_local_binary_pattern.html)_ da biblioteca _skimage_ o mesmo processo descrito anteriormente, para a extração de features de histogramas, foi aplicado."],"metadata":{"id":"DlV7P19HeH2c"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wCsWRjDK9vnD"},"outputs":[],"source":["# Função para extrair features da Local Binary Pattern (LBP) das imagens\n","def makeLBP(image: np.array, n_points: int, radius: int, method: str) -> np.array:\n","  \"\"\"\n","  ## Descrição:\n","    - Aplica LBP a imagem e gera histograma a partir\n","    do resultado obtido\n","\n","  ## Entrada:\n","    - image: np.array correspondentes ao ROI de uma imagem\n","    - n_points: int contendo o número de pontos vizinhos \n","    circularmente que serão avaliados pela LBP\n","    - radius: int contendo o valor de raio utilizado para\n","    aplicação da LBP\n","    - method: String contendo método utilizado para\n","    aplicação da LBP\n","  \n","  ## Saída:\n","    - hist: Array contendo o histograma gerado a partir da image recebida\n","  \"\"\"\n","  lbp = local_binary_pattern(image, n_points, radius, method)\n","  bins=30\n","  # Calculo histograma já eliminando os pixels pretos da imagem\n","  hist, x = np.histogram(lbp[lbp>0], bins) \n","\n","  return hist\n","\n","def get_LBP_features(imgs: list) -> list:\n","  \"\"\"\n","  ## Descrição:\n","    - Obtem features provenientes dos histogramas apos a aplicaçãpo\n","    da LBP nas imagens recebidas\n","\n","  ## Entrada:\n","    - imgs: Lista de np.array correspondentes aos ROIs das imagens\n","  \n","  ## Saída:\n","    - lbp_features: Lista de dicionários contendo as features extraídas\n","    dos histogramas construídos após a aplicação da LBP\n","  \"\"\"\n","\n","  # Cria estrutura para armazenar as features\n","  lbp_features = []\n","\n","  # Percorre imagens aplicando a LBP\n","  for i in range(len(imgs)):\n","    lbp_hist = makeLBP(imgs[i], 3*8, 3, 'uniform')\n","    describe = stats.describe(lbp_hist)._asdict()\n","    lbp_features.append( {'min_LBP': describe['minmax'][0],\n","                          'max_LBP': describe['minmax'][1],\n","                          'mean_LBP': describe['mean'],\n","                          'variance_LBP': describe['variance'],\n","                          'skewness_LBP': describe['skewness'],\n","                          'kurtosis_LBP': describe['kurtosis']} )\n","  \n","  return lbp_features"]},{"cell_type":"markdown","metadata":{"id":"dbHNnggeeGw5"},"source":["## Extração e Montagem dos Datasets"]},{"cell_type":"markdown","source":["Ao final do processo de extração de atributos são gerados 3 datasets, um destinado a lesões isquêmicas(AVC), outro para desmielinizantes(EM) e um último abrigando as lesões de pacientes com Lúpus Eritematoso Sistêmico(LES). Além de trazer as features já mencionadas, os datasets também abrigam o identificador do paciente e uma feature correspondente a área da lesão, extraída durante a seleção das imagens. Ainda, para as lesões isquêmicas e desmielinizantes há um rótulo indicando esse tipo, utilizado para o treinamento do modelo. Ao final o dataset deve apresentar as informações contidas na Tabela 1.\n","\n","|Coluna|Descrição|\n","|---|---|\n","|patient| Id do paciente que originou a imagem|\n","|min| Menor valor encontrado no histograma|\n","|max| Maior valor encontrado no histograma|\n","|mean| Média aritmética dos valores presentes no histograma|\n","|variance| Variância dos valores encontrados no histograma|\n","|skewness| Assimetria ou Obliquidade do histograma |\n","|kurtosis| Curtose, medida da forma que caracteriza a cauda do histograma|\n","|contrast_sum| Soma do contraste, diferença entre os tons de cinza, para os ângulos 0º, 45º, 90º e 135º|\n","|correlation_sum| Soma da correlação, dependência linear dos tons de cinza, para os ângulos 0º, 45º, 90º e 135º|\n","|energy_sum| Soma da energia, uniformidade da textura, para os ângulos 0º, 45º, 90º e 135º|\n","|homogeneity_sum| Soma da homogeneidade, medida da variação da textura, para os ângulos 0º, 45º, 90º e 135º|\n","|sre| Short Run Emphasis, ênfase em corrida curta \n","|lre| Long Run Emphasis, ênfase em corrida longa\n","|glu| Grey Level Uniformity, uniformidade de tom de cinza\n","|rlu| Run Length Uniformity, uniformidade de tamanho de corrida\n","|rpc| Run Percentage, percentagem de corrida, mede predominância dos tamanhos de corrida\n","|min_LBP| Menor valor encontrado no histograma da LBP|\n","|max_LBP| Maior valor encontrado no histograma da LBP|\n","|mean_LBP| Média aritmética dos valores presentes no histograma da LBP|\n","|variance_LBP| Variância dos valores encontrado no histograma da LBP|\n","|skewness_LBP| Assimetria ou Obliquidade do histograma da LBP|\n","|kurtosis_LBP| Curtose, medida da forma que caracteriza a cauda do histograma da LBP|\n","|area| Número de pixels com valor maior que zero presentes nas imagem|\n","|target| Grupo ao qual o paciente pertence(AVC/EM)|\n","\n","_Tabela 1: Atributos extraídos do conjunto de imagens._\n","\n"],"metadata":{"id":"CDuMSzWRue-T"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8cyCBG-bXxK"},"outputs":[],"source":["# Realiza extração de features e as retorna tabuladas em um pandas dataframe\n","def extract_features(roi_dict: dict, target:str) -> pd.DataFrame:\n","  \"\"\"\n","  ## Descrição:\n","    - Realiza a extração de features, para um determinado conjunto\n","    imagens, fazendo uso das funções anteriores\n","\n","  ## Entrada:\n","    - roi_dict: Dicionário de np.array, correspondentes aos ROIs das imagens,\n","    e suas áreas \n","    - target: String com a informação do grupo de origem das imagens fornecidas\n","  \n","  ## Saída:\n","    - new_features: DataFrame contento todas as features extraídas para\n","    o conjunto de imagens fornecido\n","  \"\"\"\n","\n","  # Inicializa DataFrame\n","  new_features = pd.DataFrame(columns=['patient', 'min', 'max', 'mean',\n","                                       'variance', 'skewness', 'kurtosis',\n","                                       'contrast_sum', 'correlation_sum',\n","                                       'energy_sum', 'homogeneity_sum',\n","                                       'sre', 'lre', 'glu', 'rlu', 'rpc',\n","                                       'min_LBP', 'max_LBP', 'mean_LBP',\n","                                       'variance_LBP', 'skewness_LBP',\n","                                       'kurtosis_LBP', 'area'])\n","  # Percorre conjunto de pacientes\n","  for patient in roi_dict.keys():\n","    # Usa as funções anteriores para obter as features \n","    glcm_features = get_GLCM_features(roi_dict[patient]['roi_imgs'])\n","    glrlm_features = get_GLRLM_features(roi_dict[patient]['roi_imgs'])\n","    hists_fetures = get_hists_features(roi_dict[patient]['roi_imgs'])\n","    lbp_features = get_LBP_features(roi_dict[patient]['roi_imgs'])\n","\n","    # Adiciona informações ao DataFrame\n","    for i in range(len(roi_dict[patient]['roi_imgs'])):\n","      new_row = {'patient':patient, **hists_fetures[i],\n","                 **glcm_features[i], **glrlm_features[i], **lbp_features[i], 'area':roi_dict[patient]['areas'][i]}\n","\n","      new_features = new_features.append(new_row, ignore_index=True)\n","    print('patient: ', patient)\n","\n","  # Ordena DataFrame gerado com base nos ids dos pacientes\n","  new_features = new_features.sort_values(by=['patient'])\n","\n","  # Adiciona coluna com o target, grupo de origem das imagens fornecidas\n","  if(target!='LES'):\n","    new_features['target'] = target\n","  \n","  return new_features"]},{"cell_type":"code","source":["# Extrai features das imagens de AVC\n","avc_features = extract_features(avc_roi_dict, 'AVC')"],"metadata":{"id":"ry4r3tVFiP_k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657137121869,"user_tz":180,"elapsed":419432,"user":{"displayName":"Cristiano Sampaio Pinheiro","userId":"00821319322819515045"}},"outputId":"6596fb85-3b63-4437-903c-4f67506e0e0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["patient:  006\n","patient:  007\n","patient:  008\n","patient:  009\n","patient:  010\n","patient:  011\n","patient:  012\n","patient:  013\n","patient:  014\n","patient:  015\n","patient:  016\n","patient:  017\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["patient:  018\n","patient:  019\n","patient:  020\n","patient:  021\n","patient:  022\n","patient:  023\n","patient:  024\n","patient:  025\n","patient:  026\n","patient:  028\n","patient:  029\n","patient:  030\n","patient:  031\n","patient:  032\n","patient:  033\n","patient:  034\n","patient:  035\n","patient:  036\n","patient:  037\n","patient:  038\n","patient:  039\n","patient:  040\n","patient:  041\n","patient:  042\n","patient:  043\n","patient:  044\n","patient:  045\n","patient:  046\n","patient:  047\n","patient:  048\n","patient:  049\n","patient:  050\n","patient:  051\n","patient:  001\n","patient:  002\n","patient:  003\n","patient:  004\n","patient:  005\n"]}]},{"cell_type":"code","source":["# Extrai features das imagens de EM\n","em_features = extract_features(em_roi_dict, 'EM')"],"metadata":{"id":"Cu_kiqfVnfkj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657137465682,"user_tz":180,"elapsed":343827,"user":{"displayName":"Cristiano Sampaio Pinheiro","userId":"00821319322819515045"}},"outputId":"7b5d32fe-0930-4eaa-c7d1-5392a2069109"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["patient:  060\n","patient:  061\n","patient:  062\n","patient:  063\n","patient:  064\n","patient:  065\n","patient:  066\n","patient:  067\n","patient:  068\n","patient:  069\n","patient:  070\n","patient:  071\n","patient:  072\n","patient:  073\n","patient:  074\n","patient:  075\n","patient:  076\n","patient:  077\n","patient:  078\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["patient:  079\n","patient:  080\n","patient:  081\n","patient:  082\n","patient:  083\n","patient:  084\n","patient:  085\n","patient:  086\n","patient:  087\n","patient:  088\n","patient:  089\n","patient:  090\n","patient:  091\n","patient:  092\n","patient:  093\n","patient:  094\n","patient:  095\n","patient:  096\n","patient:  097\n","patient:  098\n","patient:  099\n","patient:  100\n","patient:  101\n","patient:  102\n","patient:  103\n","patient:  104\n","patient:  105\n","patient:  106\n","patient:  107\n","patient:  108\n","patient:  109\n","patient:  120\n"]}]},{"cell_type":"code","source":["# Extrai features das imagens de LES\n","les_features = extract_features(les_roi_dict, 'LES')"],"metadata":{"id":"Lax1lHVesw8Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657137836428,"user_tz":180,"elapsed":370751,"user":{"displayName":"Cristiano Sampaio Pinheiro","userId":"00821319322819515045"}},"outputId":"a626a72f-2463-4172-ecfa-046781aca3f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["patient:  625\n","patient:  626\n","patient:  627\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["patient:  628\n","patient:  629\n","patient:  630\n","patient:  631\n","patient:  632\n","patient:  633\n","patient:  634\n","patient:  635\n","patient:  636\n","patient:  637\n","patient:  638\n","patient:  639\n","patient:  640\n","patient:  641\n","patient:  642\n","patient:  643\n","patient:  644\n","patient:  645\n","patient:  646\n","patient:  647\n","patient:  648\n","patient:  649\n","patient:  650\n","patient:  651\n","patient:  652\n","patient:  653\n","patient:  654\n","patient:  655\n","patient:  656\n","patient:  657\n","patient:  658\n","patient:  659\n","patient:  660\n","patient:  661\n","patient:  662\n","patient:  663\n","patient:  664\n","patient:  665\n","patient:  666\n","patient:  667\n","patient:  668\n","patient:  669\n","patient:  671\n","patient:  672\n","patient:  673\n","patient:  674\n","patient:  675\n","patient:  676\n","patient:  677\n","patient:  678\n","patient:  600\n","patient:  601\n","patient:  602\n","patient:  603\n","patient:  604\n","patient:  605\n","patient:  606\n","patient:  607\n","patient:  608\n","patient:  609\n","patient:  610\n","patient:  611\n","patient:  612\n","patient:  613\n","patient:  614\n","patient:  615\n","patient:  616\n","patient:  617\n","patient:  618\n","patient:  619\n","patient:  620\n","patient:  621\n","patient:  622\n","patient:  623\n","patient:  624\n"]}]},{"cell_type":"code","source":["les_features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"mvvZQ5qLIzLk","executionInfo":{"status":"ok","timestamp":1657139348738,"user_tz":180,"elapsed":293,"user":{"displayName":"Cristiano Sampaio Pinheiro","userId":"00821319322819515045"}},"outputId":"f19a1a23-eb64-49aa-8ebb-e5caba8c1f42"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    patient min max  mean    variance  skewness  kurtosis  contrast_sum  \\\n","502     600   0  19  3.50   41.526316  1.542482  0.794932  38637.883965   \n","503     600   0  16  2.95   26.050000  1.426048  0.611286    405.368930   \n","507     600   0   6  0.50    2.157895  3.066279  8.365259    404.735714   \n","506     600   0  26  2.40   44.357895  2.824562  6.713903    222.387630   \n","505     600   0  12  1.90   14.200000  1.659997  1.177323    821.411667   \n","..      ...  ..  ..   ...         ...       ...       ...           ...   \n","493     677   0   4  0.55    1.102632  2.103602  3.922477   1700.250000   \n","494     677   0   1  0.10    0.094737  2.666667  5.111111           NaN   \n","497     678   0  42  6.35  132.660526  1.932754  2.792044  60541.444794   \n","495     678   0  18  5.05   38.365789  1.007466 -0.374500   7476.873001   \n","496     678   0  22  8.50   41.421053  0.521996 -0.694032  19170.696297   \n","\n","     correlation_sum  energy_sum  ...        glu      rlu    rpc  min_LBP  \\\n","502         0.657117    0.423841  ...  95786.581  268.176  0.008        0   \n","503         3.442599    0.464100  ...  11266.245  215.454  0.012        0   \n","507         1.184195    1.283656  ...     12.000   40.000  0.040        0   \n","506         2.222683    0.529743  ...     43.796  171.843  0.066        0   \n","505         1.972492    0.563551  ...  13084.806  143.162  0.008        0   \n","..               ...         ...  ...        ...      ...    ...      ...   \n","493         0.499005    1.122164  ...     10.908   44.000  0.044        0   \n","494              NaN         NaN  ...     10.000    8.000  0.016        0   \n","497         1.069504    0.318871  ...   7790.279  463.812  0.022        0   \n","495         1.283923    0.335953  ...  16106.446  392.121  0.016        0   \n","496         2.467049    0.259991  ...   8311.701  653.325  0.026        0   \n","\n","     max_LBP    mean_LBP  variance_LBP skewness_LBP  kurtosis_LBP  area  \n","502    10300  344.833333  3.535281e+06     5.199438     25.034270    77  \n","503     5401  181.233333  9.719192e+05     5.199418     25.034135    65  \n","507        2    0.166667  2.816092e-01     2.998808      7.389421    13  \n","506       62    3.200000  1.278207e+02     4.919141     23.104999    53  \n","505     3796  127.266667  4.801310e+05     5.199427     25.034197    44  \n","..       ...         ...           ...          ...           ...   ...  \n","493        1    0.100000  9.310345e-02     2.666667      5.111111    13  \n","494        0    0.000000  0.000000e+00     0.000000     -3.000000     4  \n","497     1742   61.100000  1.008455e+05     5.194759     25.002608   135  \n","495     8591  289.000000  2.458638e+06     5.199396     25.033994   104  \n","496     8314  281.433333  2.301715e+06     5.199132     25.032220   175  \n","\n","[691 rows x 23 columns]"],"text/html":["\n","  <div id=\"df-12a46395-ad46-409a-a129-c6a0df7877fa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>patient</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>mean</th>\n","      <th>variance</th>\n","      <th>skewness</th>\n","      <th>kurtosis</th>\n","      <th>contrast_sum</th>\n","      <th>correlation_sum</th>\n","      <th>energy_sum</th>\n","      <th>...</th>\n","      <th>glu</th>\n","      <th>rlu</th>\n","      <th>rpc</th>\n","      <th>min_LBP</th>\n","      <th>max_LBP</th>\n","      <th>mean_LBP</th>\n","      <th>variance_LBP</th>\n","      <th>skewness_LBP</th>\n","      <th>kurtosis_LBP</th>\n","      <th>area</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>502</th>\n","      <td>600</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>3.50</td>\n","      <td>41.526316</td>\n","      <td>1.542482</td>\n","      <td>0.794932</td>\n","      <td>38637.883965</td>\n","      <td>0.657117</td>\n","      <td>0.423841</td>\n","      <td>...</td>\n","      <td>95786.581</td>\n","      <td>268.176</td>\n","      <td>0.008</td>\n","      <td>0</td>\n","      <td>10300</td>\n","      <td>344.833333</td>\n","      <td>3.535281e+06</td>\n","      <td>5.199438</td>\n","      <td>25.034270</td>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>503</th>\n","      <td>600</td>\n","      <td>0</td>\n","      <td>16</td>\n","      <td>2.95</td>\n","      <td>26.050000</td>\n","      <td>1.426048</td>\n","      <td>0.611286</td>\n","      <td>405.368930</td>\n","      <td>3.442599</td>\n","      <td>0.464100</td>\n","      <td>...</td>\n","      <td>11266.245</td>\n","      <td>215.454</td>\n","      <td>0.012</td>\n","      <td>0</td>\n","      <td>5401</td>\n","      <td>181.233333</td>\n","      <td>9.719192e+05</td>\n","      <td>5.199418</td>\n","      <td>25.034135</td>\n","      <td>65</td>\n","    </tr>\n","    <tr>\n","      <th>507</th>\n","      <td>600</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0.50</td>\n","      <td>2.157895</td>\n","      <td>3.066279</td>\n","      <td>8.365259</td>\n","      <td>404.735714</td>\n","      <td>1.184195</td>\n","      <td>1.283656</td>\n","      <td>...</td>\n","      <td>12.000</td>\n","      <td>40.000</td>\n","      <td>0.040</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.166667</td>\n","      <td>2.816092e-01</td>\n","      <td>2.998808</td>\n","      <td>7.389421</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>506</th>\n","      <td>600</td>\n","      <td>0</td>\n","      <td>26</td>\n","      <td>2.40</td>\n","      <td>44.357895</td>\n","      <td>2.824562</td>\n","      <td>6.713903</td>\n","      <td>222.387630</td>\n","      <td>2.222683</td>\n","      <td>0.529743</td>\n","      <td>...</td>\n","      <td>43.796</td>\n","      <td>171.843</td>\n","      <td>0.066</td>\n","      <td>0</td>\n","      <td>62</td>\n","      <td>3.200000</td>\n","      <td>1.278207e+02</td>\n","      <td>4.919141</td>\n","      <td>23.104999</td>\n","      <td>53</td>\n","    </tr>\n","    <tr>\n","      <th>505</th>\n","      <td>600</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>1.90</td>\n","      <td>14.200000</td>\n","      <td>1.659997</td>\n","      <td>1.177323</td>\n","      <td>821.411667</td>\n","      <td>1.972492</td>\n","      <td>0.563551</td>\n","      <td>...</td>\n","      <td>13084.806</td>\n","      <td>143.162</td>\n","      <td>0.008</td>\n","      <td>0</td>\n","      <td>3796</td>\n","      <td>127.266667</td>\n","      <td>4.801310e+05</td>\n","      <td>5.199427</td>\n","      <td>25.034197</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>493</th>\n","      <td>677</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.55</td>\n","      <td>1.102632</td>\n","      <td>2.103602</td>\n","      <td>3.922477</td>\n","      <td>1700.250000</td>\n","      <td>0.499005</td>\n","      <td>1.122164</td>\n","      <td>...</td>\n","      <td>10.908</td>\n","      <td>44.000</td>\n","      <td>0.044</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.100000</td>\n","      <td>9.310345e-02</td>\n","      <td>2.666667</td>\n","      <td>5.111111</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>494</th>\n","      <td>677</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.10</td>\n","      <td>0.094737</td>\n","      <td>2.666667</td>\n","      <td>5.111111</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>10.000</td>\n","      <td>8.000</td>\n","      <td>0.016</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000</td>\n","      <td>-3.000000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>678</td>\n","      <td>0</td>\n","      <td>42</td>\n","      <td>6.35</td>\n","      <td>132.660526</td>\n","      <td>1.932754</td>\n","      <td>2.792044</td>\n","      <td>60541.444794</td>\n","      <td>1.069504</td>\n","      <td>0.318871</td>\n","      <td>...</td>\n","      <td>7790.279</td>\n","      <td>463.812</td>\n","      <td>0.022</td>\n","      <td>0</td>\n","      <td>1742</td>\n","      <td>61.100000</td>\n","      <td>1.008455e+05</td>\n","      <td>5.194759</td>\n","      <td>25.002608</td>\n","      <td>135</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>678</td>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>5.05</td>\n","      <td>38.365789</td>\n","      <td>1.007466</td>\n","      <td>-0.374500</td>\n","      <td>7476.873001</td>\n","      <td>1.283923</td>\n","      <td>0.335953</td>\n","      <td>...</td>\n","      <td>16106.446</td>\n","      <td>392.121</td>\n","      <td>0.016</td>\n","      <td>0</td>\n","      <td>8591</td>\n","      <td>289.000000</td>\n","      <td>2.458638e+06</td>\n","      <td>5.199396</td>\n","      <td>25.033994</td>\n","      <td>104</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>678</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>8.50</td>\n","      <td>41.421053</td>\n","      <td>0.521996</td>\n","      <td>-0.694032</td>\n","      <td>19170.696297</td>\n","      <td>2.467049</td>\n","      <td>0.259991</td>\n","      <td>...</td>\n","      <td>8311.701</td>\n","      <td>653.325</td>\n","      <td>0.026</td>\n","      <td>0</td>\n","      <td>8314</td>\n","      <td>281.433333</td>\n","      <td>2.301715e+06</td>\n","      <td>5.199132</td>\n","      <td>25.032220</td>\n","      <td>175</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>691 rows × 23 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12a46395-ad46-409a-a129-c6a0df7877fa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-12a46395-ad46-409a-a129-c6a0df7877fa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-12a46395-ad46-409a-a129-c6a0df7877fa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# Salvar dataFrames como CSV\n","# avc_features.to_csv(PATH_DATA+\"avc_features.csv\", index=False)\n","# em_features.to_csv(PATH_DATA+\"em_features.csv\", index=False)\n","# les_features.to_csv(PATH_DATA+\"les_features.csv\", index=False)"],"metadata":{"id":"OXJPgPeJqEkb"},"execution_count":null,"outputs":[]}]}